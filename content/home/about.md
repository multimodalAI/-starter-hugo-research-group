---
# A Demo section created with the Blank widget.
# Any elements can be added in the body: https://wowchemy.com/docs/writing-markdown-latex/
# Add more sections by duplicating this file and customizing to your requirements.
widget: blank
headless: true # This file represents a page section.

weight: 20 # Order that this section will appear.
title:
hero_media: 
design:
  # Choose how many columns the section has. Valid values: 1 or 2.
  columns: '1'
  # Add custom styles
  css_style:
  css_class:
---

Multimodal AI combines multiple types of data (image, text, audio, etc) via machine learning models and algorithms to achieve better performance. Multimodal AI is key for AI research and applications including healthcare, net zero, finance, robotics, and manufacturing. Multimodal AI in these areas is challenging due to the inherent complexity of data integration and the limited availability of labelled data. Unimodal AI for a single type of data input is maturing at an accelerating pace, thus creating vast opportunities for tackling multimodal AI challenges.

MultimodalAI’23 brings together researchers and practitioners from AI, data science, and various scientific and application domains to discuss problems and challenges, share experiences and solutions, explore collaborations and future directions, and build networks and a vibrant community on multimodal AI. We have three keynote speakers covering academic research, industrial research, and industrial applications: [Professor Mirella Lapata](https://homepages.inf.ed.ac.uk/mlap/) (University of Edinburgh, UKRI Turing AI World-Leading Researcher Fellow), [Dr Yutian Chen](https://www.cantab.net/users/yutian.chen/index.html) (Google DeepMind, AlphaGo Developer), and [Dr Chew-Yean Yam](https://www.linkedin.com/in/cyyam/?originalSubdomain=uk) (Microsoft, Principal Data and Applied Scientist).

We offer participants opportunities to give 3-min pitches and present posters, with four prizes (£150 each) in total for the best pitches and best posters.  You may submit proposals for a pitch and/or poster when you [register](https://onlineshop.shef.ac.uk/conferences-and-events/faculty-of-engineering/faculty-of-engineering/first-workshop-on-multimodal-ai). We will confirm accepted pitches and posters in the week ending June 17th. 

Should you require assistance with accessibility for this event or if you have any other special requirements please  let us know via the [registration form](https://onlineshop.shef.ac.uk/conferences-and-events/faculty-of-engineering/faculty-of-engineering/first-workshop-on-multimodal-ai) and/or [contact us](#contact) if you would like to discuss your needs with the organising team.  We will do our best to fulfil your requirements to allow you to fully participate in this event.

We also have funds to cover travel costs for those who need support to attend.

Join this interdisciplinary event to create a diverse community that shapes and builds the future of multimodal AI research and developments.

**Welcome to share the workshop flyer in [PDF](media/flyer.pdf) and [PNG](media/flyer.png) with your network.**
