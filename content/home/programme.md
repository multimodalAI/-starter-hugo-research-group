---
# An instance of the People widget.
# Documentation: https://wowchemy.com/docs/page-builder/
widget: people

# This file represents a page section.
headless: true

# Order that this section appears on the page.
weight: 20

title: Tentative Programme (In Person Only)
subtitle: Wednesday, 22nd November 2023

content:
  # Choose which groups/teams of users to display.
  #   Edit `user_groups` in each user's profile to add them to one or more of these groups.
#  user_groups:
#    - Principal Investigators
#    - Researchers
#    - Grad Students
#    - Administration
#    - Visitors
#   - Alumni
design:
  show_interests: false
  show_role: true
  show_social: true
---
<center>

| Time          | &nbsp;&nbsp;&nbsp;&nbsp;Event                                 |
|---------------|---------------------------------------------------------------|
| 10:00 - 10:15 | &nbsp;&nbsp;&nbsp;&nbsp;Welcome and Introduction              |
| 10:15 - 11:00 | &nbsp;&nbsp;&nbsp;&nbsp;Pitch Session                         |
| 11:00 - 11:15 | &nbsp;&nbsp;&nbsp;&nbsp;Coffee Break                          |
| 11:15 - 12:00 | &nbsp;&nbsp;&nbsp;&nbsp;Breakout Session 1                    |
| 12:00 - 12:30 | &nbsp;&nbsp;&nbsp;&nbsp;Breakout Reflection and Consolidation |
| 12:30 - 13:30 | &nbsp;&nbsp;&nbsp;&nbsp;Lunch (provided)                      |
| 13:30 - 15:30 | &nbsp;&nbsp;&nbsp;&nbsp;Breakout Session 2                    |
| 15:30 - 16:00 | &nbsp;&nbsp;&nbsp;&nbsp;Consolidation and Next Steps          |
</center>

<center>

<p style="font-size: 24px; font-weight: bold;">Pitches</p>

| Name               | &nbsp;&nbsp;&nbsp;&nbsp;Title                                                                                   |
|--------------------|-----------------------------------------------------------------------------------------|
| Peter Charlton    | &nbsp;&nbsp;&nbsp;&nbsp;Using multimodal AI to diagnose atrial fibrillation from smart wearables                |
| Yuhan Wang        | &nbsp;&nbsp;&nbsp;&nbsp;Explainable Alzheimer Disease Early Detection Framework Based on Multi-Modal Clinical Data |
| Mohammod Suvon    | &nbsp;&nbsp;&nbsp;&nbsp;Multimodal Cardiothoracic Disease Prediction                                             |
| Chris Tomlinson   | &nbsp;&nbsp;&nbsp;&nbsp;graphICM: graph and semantic representation learning for critical illness aetiology     |
| Avish Vijayaraghavan | &nbsp;&nbsp;&nbsp;&nbsp;Interpretable Multi-Modal Learning for Clinical Multi-Omics                             |
| Luigi Moretti     | &nbsp;&nbsp;&nbsp;&nbsp;Can MultimodalAI be effectively implemented to help treat Anxiety Disorders?            |
| Lucas Farndale    | &nbsp;&nbsp;&nbsp;&nbsp;Super Vision Without Supervision: Self-Supervised Multimodal Privileged Information Integration for Enhanced Biomedical Imaging |
| Jinge Wu          | &nbsp;&nbsp;&nbsp;&nbsp;Facilitating factual checking on radiology reports using multimodal benchmark datasets  |
| Greg Slabaugh     | &nbsp;&nbsp;&nbsp;&nbsp;Multimodal AI for Multi'omics Data Integration in Healthcare                            |
| Chen Chen         | &nbsp;&nbsp;&nbsp;&nbsp;Towards Responsible AI in Healthcare: Enhancing Generalizability, Robustness, Explainability, and Fairness with Multi-modality Data |
| Owen Rackham      | &nbsp;&nbsp;&nbsp;&nbsp;Multimodal data in cell and molecular medicine                                          |
| Marta Varela      | &nbsp;&nbsp;&nbsp;&nbsp;Physics-Informed Neural Networks                                                        |
| Oya Celiktutan    | &nbsp;&nbsp;&nbsp;&nbsp;Multimodal Behavioural AI for Human-Robot Interaction                                   |
| Nitisha Jain      | &nbsp;&nbsp;&nbsp;&nbsp;Semantic Interpretations of Multimodal Embeddings towards Explainable AI                |
| Roger Moore       | &nbsp;&nbsp;&nbsp;&nbsp;Vocal interactivity in a multimodal context: pragmatic, synchronic and energetic constraints |
| Ruizhe Li         | &nbsp;&nbsp;&nbsp;&nbsp;Hearing Lips in Noise: Fusing Acoustic and Visual Data for Noise-Robust Speech Recognition |
| Emmanouil Benetos | &nbsp;&nbsp;&nbsp;&nbsp;Audio-language representation learning                                                   |
| Cyndie Demeocq    | &nbsp;&nbsp;&nbsp;&nbsp;Data annotation and curation for multimodal methods in online crime detection systems   |
| Valentin Danchev  | &nbsp;&nbsp;&nbsp;&nbsp;Data Governance and Responsible Sharing of Multimodal Data for AI Research              |
| Salah (Sam) Hammouche | &nbsp;&nbsp;&nbsp;&nbsp;Beyond Compliance in AI Evaluation & Federated Learning                                 |
| Lucia Cipolina-Kun | &nbsp;&nbsp;&nbsp;&nbsp;Diffusion models for the restoration of cultural heritage                               |
| Pin Ni            | &nbsp;&nbsp;&nbsp;&nbsp;Financial multi-modal fusion and learning                                               |
| Arunav Das        | &nbsp;&nbsp;&nbsp;&nbsp;Multimodal Knowledge Graph based Question Answering system                              |
| Thijs van der Plas | &nbsp;&nbsp;&nbsp;&nbsp;Biodiversity monitoring                                                                 |
| Alejandro Coca-Castro | &nbsp;&nbsp;&nbsp;&nbsp;Environmental Data Modalities: Challenges and Opportunities                             |

</center>
