---
# A Demo section created with the Blank widget.
# Any elements can be added in the body: https://wowchemy.com/docs/writing-markdown-latex/
# Add more sections by duplicating this file and customizing to your requirements.
widget: blank
headless: true # This file represents a page section.

weight: 20 # Order that this section will appear.
title:
hero_media: 
design:
  # Choose how many columns the section has. Valid values: 1 or 2.
  columns: '1'
  # Add custom styles
  css_style:
  css_class:
---




<details>
<summary style="font-size: 24px; border: none;">About</summary>
<p style="border: none; margin-left: 0;">
Multimodal AI combines multiple types of data (image, text, audio, etc) via machine learning models and algorithms to achieve better performance. Multimodal AI is key for AI research and applications including healthcare, net zero, finance, robotics, and manufacturing. Multimodal AI in these areas is challenging due to the inherent complexity of data integration and the limited availability of labelled data. Unimodal AI for a single type of data input is maturing at an accelerating pace, thus creating vast opportunities for tackling multimodal AI challenges.
</p><p style="border: none; margin-left: 0;">
MultimodalAI’23 brings together researchers and practitioners from AI, data science, and various scientific and application domains to discuss problems and challenges, share experiences and solutions, explore collaborations and future directions, and build networks and a vibrant community on multimodal AI. We have three keynote speakers covering academic research, industrial research, and industrial applications: <a href="https://homepages.inf.ed.ac.uk/mlap/">Professor Mirella Lapata</a> (University of Edinburgh, UKRI Turing AI World-Leading Researcher Fellow), <a href="https://www.cantab.net/users/yutian.chen/index.html">Dr Yutian Chen</a> (Google DeepMind, AlphaGo Developer), and <a href="https://www.linkedin.com/in/cyyam/?originalSubdomain=uk">Dr Chew-Yean Yam</a> (Microsoft, Principal Data and Applied Scientist).
</p><p style="border: none; margin-left: 0;">
We offer participants opportunities to give 3-min pitches and present posters, with four prizes (£150 each) in total for the best pitches and best posters. You may submit proposals for a pitch and/or poster when you register. We will confirm accepted pitches and posters in the week ending June 17th.
</p><p style="border: none; margin-left: 0;">
Should you require assistance with accessibility for this event, or if you have any other special requirements, or if you would like to discuss your needs with the organizing team, please <a href="#contact">contact us</a>. We will do our best to fulfill your requirements to allow you to fully participate in this event.
</p><p style="border: none; margin-left: 0;">
Join this interdisciplinary event to create a diverse community that shapes and builds the future of multimodal AI research and developments.
</p><p style="border: none; margin-left: 0;">
<b>Welcome to share the workshop flyer in <a href="media/flyer.pdf">PDF</a> with your network.</b>
</p>
</details>

