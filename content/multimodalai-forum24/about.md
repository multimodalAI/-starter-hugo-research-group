---
# A Demo section created with the Blank widget.
# Any elements can be added in the body: https://wowchemy.com/docs/writing-markdown-latex/
# Add more sections by duplicating this file and customizing to your requirements.
widget: blank
headless: true # This file represents a page section.

weight: 10 # Order that this section will appear.
title: First Multimodal AI Community Forum
hero_media: 
design:
  # Choose how many columns the section has. Valid values: 1 or 2.
  columns: '1'
  # Add custom styles
  css_style:
  css_class:
---
<details>
<summary style="font-size: 24px; border: none;">Show</summary>
<p style="border: none; margin-left: 0;">
Welcome to "<strong>The First Multimodal AI Community Forum</strong>", an online <a href="https://ai-uk.turing.ac.uk/fringe-events/">AI UK Fringe</a> event. This event is scheduled from <strong>13:00 to 17:00 (GMT) on Monday, 25th March 2024</strong>. The deadline for <a href="https://forms.gle/yckNWD8kHY5Z1wjo9">registration</a> is <strong>Thursday, 14th March 2024, 23:59 (GMT)</strong>.
</p>
<p style="border: none; margin-left: 0;">
Multimodal AI, which integrates various data modalities such as text, image, sound, and others, is swiftly revolutionising our interaction with technology and data. In our recent Turing Interest Group event (22nd Nov), "<a href="https://multimodalai.github.io/multimodalaisprint23/">The First Multimodal AI Research Sprint</a>", we explored the diverse research states and methodologies in Multimodal AI across six areas and initiated the writing of a perspective paper on multimodal AI. Based on such past activities, this online forum aims to further bring together community members, from researchers to practitioners, to share their latest interdisciplinary perspectives and pioneering work in Multimodal AI. Our goal is to facilitate the exchange of fresh insights and foster connections and research progress within the Multimodal AI community.
</p>
<p style="border: none; margin-left: 0;">
We welcome researchers, practitioners, and students engaged in or interested in Multimodal AI from anywhere in the world to join us online. We also encourage the organisation of local community gatherings to watch and discuss the forum together.
</p>
<p style="border: none; margin-left: 0;">
The video recording of the Keynote Presentation by Chunyuan Li is given below.
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/6F4fra-QBpk?si=QAhzPnhvdKKT6Qnf&amp;start=1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
<p style="border: none; margin-left: 0;">
The video recording of the Open Discussion session of the <strong>First Multimodal AI Community Forum</strong> is given below.
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/vf6CxlJSuVk?si=-CeaLFU7BDpBt-gt" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</details>
